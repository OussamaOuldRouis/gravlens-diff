{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from scipy import linalg\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Data parameters\n",
    "        self.data_path = \"extracted_data/Samples\"\n",
    "        self.image_size = 128\n",
    "        self.channels = 1  # Grayscale images\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 10\n",
    "        self.lr = 2e-4\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # DDPM parameters\n",
    "        self.timesteps = 1000\n",
    "        self.beta_start = 1e-4\n",
    "        self.beta_end = 0.02\n",
    "\n",
    "        # Model parameters\n",
    "        self.hidden_dims = [64, 128, 256, 512]\n",
    "        self.num_res_blocks = 2\n",
    "        \n",
    "        # Inference settings (for later use)\n",
    "        self.model_path = None  # Will be set when loading from HuggingFace\n",
    "        self.fid_n_samples = 16\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Dataset class\n",
    "class LensingDataset(Dataset):\n",
    "    def __init__(self, data_path, image_size, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.file_list = [f for f in os.listdir(data_path) if f.endswith('.npy')]\n",
    "        self.image_size = image_size\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((self.image_size, self.image_size), antialias=True),\n",
    "                transforms.Normalize((0.5,), (0.5,))\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_path, self.file_list[idx])\n",
    "        image = np.load(file_path).astype(np.float32)\n",
    "\n",
    "        # Normalize to [0, 1]\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "        if max_val > min_val:\n",
    "            image = (image - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            image = np.zeros_like(image)\n",
    "\n",
    "        # Handle different shapes\n",
    "        if len(image.shape) == 1:\n",
    "            size = int(np.sqrt(image.shape[0]))\n",
    "            if size * size == image.shape[0]:\n",
    "                image = image.reshape(size, size)\n",
    "            else:\n",
    "                closest_factor = int(np.sqrt(image.shape[0]))\n",
    "                while image.shape[0] % closest_factor != 0 and closest_factor > 1:\n",
    "                    closest_factor -= 1\n",
    "                if closest_factor > 1:\n",
    "                    other_dim = image.shape[0] // closest_factor\n",
    "                    image = image.reshape(closest_factor, other_dim)\n",
    "                else:\n",
    "                    image = np.resize(image, (self.image_size, self.image_size))\n",
    "        elif len(image.shape) == 3:\n",
    "            if image.shape[0] == 150:\n",
    "                image = image[0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=0)\n",
    "\n",
    "        if len(image.shape) != 2:\n",
    "            image = np.resize(image, (self.image_size, self.image_size))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image.float()\n",
    "\n",
    "# Diffusion schedule helper\n",
    "def get_noise_schedule(config):\n",
    "    \"\"\"Linear beta schedule for diffusion model.\"\"\"\n",
    "    beta = np.linspace(config.beta_start, config.beta_end, config.timesteps)\n",
    "    sqrt_beta = np.sqrt(beta)\n",
    "    alpha = 1 - beta\n",
    "    alpha_bar = np.cumprod(alpha)\n",
    "    sqrt_alpha_bar = np.sqrt(alpha_bar)\n",
    "    sqrt_one_minus_alpha_bar = np.sqrt(1 - alpha_bar)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    beta = torch.tensor(beta, dtype=torch.float32).to(config.device)\n",
    "    sqrt_beta = torch.tensor(sqrt_beta, dtype=torch.float32).to(config.device)\n",
    "    alpha = torch.tensor(alpha, dtype=torch.float32).to(config.device)\n",
    "    alpha_bar = torch.tensor(alpha_bar, dtype=torch.float32).to(config.device)\n",
    "    sqrt_alpha_bar = torch.tensor(sqrt_alpha_bar, dtype=torch.float32).to(config.device)\n",
    "    sqrt_one_minus_alpha_bar = torch.tensor(sqrt_one_minus_alpha_bar, dtype=torch.float32).to(config.device)\n",
    "\n",
    "    return {\n",
    "        'beta': beta,\n",
    "        'sqrt_beta': sqrt_beta,\n",
    "        'alpha': alpha,\n",
    "        'alpha_bar': alpha_bar,\n",
    "        'sqrt_alpha_bar': sqrt_alpha_bar,\n",
    "        'sqrt_one_minus_alpha_bar': sqrt_one_minus_alpha_bar,\n",
    "    }\n",
    "\n",
    "# Model components\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = np.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device, dtype=torch.float32) * -embeddings)\n",
    "        embeddings = time[:, None].float() * embeddings[None, :]\n",
    "        embeddings = torch.cat((torch.sin(embeddings), torch.cos(embeddings)), dim=-1)\n",
    "        if self.dim % 2 == 1:\n",
    "             embeddings = F.pad(embeddings, (0,1))\n",
    "        return embeddings\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, num_heads=4):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.num_heads = num_heads\n",
    "        assert channels % num_heads == 0\n",
    "        self.mha = nn.MultiheadAttention(channels, num_heads, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[-2:]\n",
    "        x = x.view(-1, self.channels, size[0] * size[1]).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, size[0], size[1])\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim=None, groups=8):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels) if time_emb_dim else None\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(min(groups, out_channels), out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(min(groups, out_channels), out_channels)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.act(self.norm1(self.conv1(x)))\n",
    "\n",
    "        if time_emb is not None and self.time_mlp is not None:\n",
    "            time_emb_proj = self.act(self.time_mlp(time_emb))\n",
    "            h = h + time_emb_proj.view(-1, time_emb_proj.shape[1], 1, 1)\n",
    "\n",
    "        h = self.act(self.norm2(self.conv2(h)))\n",
    "        return h + self.shortcut(x)\n",
    "\n",
    "# UNet model definition\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.channels = config.channels\n",
    "        self.time_dim = config.hidden_dims[0]\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(self.time_dim),\n",
    "            nn.Linear(self.time_dim, self.time_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.time_dim * 4, self.time_dim * 4)\n",
    "        )\n",
    "        time_emb_dim_unet = self.time_dim * 4\n",
    "\n",
    "        # Initial projection\n",
    "        init_dim = config.hidden_dims[0]\n",
    "        self.init_conv = nn.Conv2d(config.channels, init_dim, 3, padding=1)\n",
    "\n",
    "        # Encoder\n",
    "        self.downs = nn.ModuleList()\n",
    "        dims = config.hidden_dims\n",
    "        current_dim = init_dim\n",
    "\n",
    "        for i in range(len(dims)):\n",
    "            down_block_layers = nn.ModuleList()\n",
    "\n",
    "            for _ in range(config.num_res_blocks):\n",
    "                down_block_layers.append(ResidualBlock(current_dim, current_dim, time_emb_dim=time_emb_dim_unet))\n",
    "\n",
    "            if i >= (len(dims) - 2):\n",
    "                down_block_layers.append(SelfAttention(current_dim))\n",
    "\n",
    "            if i < len(dims) - 1:\n",
    "                down_block_layers.append(nn.Conv2d(current_dim, dims[i+1], kernel_size=4, stride=2, padding=1))\n",
    "                current_dim = dims[i+1]\n",
    "\n",
    "            self.downs.append(down_block_layers)\n",
    "\n",
    "        # Middle block\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResidualBlock(mid_dim, mid_dim, time_emb_dim=time_emb_dim_unet),\n",
    "            SelfAttention(mid_dim),\n",
    "            ResidualBlock(mid_dim, mid_dim, time_emb_dim=time_emb_dim_unet)\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.ups = nn.ModuleList()\n",
    "        for i in reversed(range(len(dims))):\n",
    "            up_block_layers = nn.ModuleList()\n",
    "\n",
    "            if i == len(dims) - 1:\n",
    "                in_dim = dims[i]\n",
    "            else:\n",
    "                in_dim = dims[i] * 2\n",
    "\n",
    "            up_block_layers.append(ResidualBlock(in_dim, dims[i], time_emb_dim=time_emb_dim_unet))\n",
    "\n",
    "            for _ in range(config.num_res_blocks - 1):\n",
    "                up_block_layers.append(ResidualBlock(dims[i], dims[i], time_emb_dim=time_emb_dim_unet))\n",
    "\n",
    "            if i >= (len(dims) - 2):\n",
    "                up_block_layers.append(SelfAttention(dims[i]))\n",
    "\n",
    "            if i > 0:\n",
    "                up_block_layers.append(nn.ConvTranspose2d(dims[i], dims[i-1], kernel_size=4, stride=2, padding=1))\n",
    "\n",
    "            self.ups.append(up_block_layers)\n",
    "\n",
    "        # Final layers\n",
    "        final_dim = dims[0]\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.GroupNorm(min(8, final_dim), final_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(final_dim, config.channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Time embedding\n",
    "        t = self.time_mlp(t)\n",
    "\n",
    "        # Initial convolution\n",
    "        x = self.init_conv(x)\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder\n",
    "        for down_block in self.downs:\n",
    "            for layer in down_block:\n",
    "                if isinstance(layer, ResidualBlock) or isinstance(layer, SelfAttention):\n",
    "                    x = layer(x, t) if isinstance(layer, ResidualBlock) else layer(x)\n",
    "                else:\n",
    "                    skip_connections.append(x)\n",
    "                    x = layer(x)\n",
    "\n",
    "        # Middle\n",
    "        for layer in self.mid:\n",
    "            x = layer(x, t) if isinstance(layer, ResidualBlock) else layer(x)\n",
    "\n",
    "        # Decoder\n",
    "        for i, up_block in enumerate(self.ups):\n",
    "            if i > 0:\n",
    "                skip = skip_connections.pop()\n",
    "                if x.shape[2:] != skip.shape[2:]:\n",
    "                    skip = F.interpolate(skip, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "                x = torch.cat([x, skip], dim=1)\n",
    "\n",
    "            for layer in up_block:\n",
    "                if isinstance(layer, ResidualBlock) or isinstance(layer, SelfAttention):\n",
    "                    x = layer(x, t) if isinstance(layer, ResidualBlock) else layer(x)\n",
    "                else:\n",
    "                    x = layer(x)\n",
    "\n",
    "        # Final convolution\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Diffusion model\n",
    "class DiffusionModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = UNet(config).to(config.device)\n",
    "        self.noise_schedule = get_noise_schedule(config)\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=config.lr)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward_diffusion(self, x_0, t):\n",
    "        \"\"\"Add noise to the input image according to the timestep t.\"\"\"\n",
    "        x_0 = x_0.float().to(self.config.device)\n",
    "        noise = torch.randn_like(x_0, dtype=torch.float32, device=self.config.device)\n",
    "        sqrt_alpha_bar = self.noise_schedule['sqrt_alpha_bar'][t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha_bar = self.noise_schedule['sqrt_one_minus_alpha_bar'][t].view(-1, 1, 1, 1)\n",
    "        x_t = sqrt_alpha_bar * x_0 + sqrt_one_minus_alpha_bar * noise\n",
    "        return x_t, noise\n",
    "\n",
    "    def train_step(self, x_0):\n",
    "        \"\"\"Single training step.\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        x_0 = x_0.float().to(self.config.device)\n",
    "        batch_size = x_0.shape[0]\n",
    "        t = torch.randint(0, self.config.timesteps, (batch_size,), device=self.config.device).long()\n",
    "        x_t, noise = self.forward_diffusion(x_0, t)\n",
    "        predicted_noise = self.model(x_t, t)\n",
    "        loss = self.loss_fn(predicted_noise, noise)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n_samples, size=None):\n",
    "        \"\"\"Sample new images using the reverse diffusion process.\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        if size is None:\n",
    "            size = (self.config.channels, self.config.image_size, self.config.image_size)\n",
    "\n",
    "        x = torch.randn((n_samples, *size), device=self.config.device, dtype=torch.float32)\n",
    "\n",
    "        for t in tqdm(reversed(range(self.config.timesteps)), desc=\"Sampling\", total=self.config.timesteps):\n",
    "            t_tensor = torch.full((n_samples,), t, device=self.config.device, dtype=torch.long)\n",
    "            predicted_noise = self.model(x, t_tensor)\n",
    "            alpha_t = self.noise_schedule['alpha'][t]\n",
    "            alpha_t_bar = self.noise_schedule['alpha_bar'][t]\n",
    "            beta_t = self.noise_schedule['beta'][t]\n",
    "            sqrt_one_minus_alpha_t_bar = self.noise_schedule['sqrt_one_minus_alpha_bar'][t]\n",
    "            sqrt_recip_alpha_t = torch.sqrt(1.0 / alpha_t)\n",
    "            mean = sqrt_recip_alpha_t * (x - (beta_t / sqrt_one_minus_alpha_t_bar) * predicted_noise)\n",
    "\n",
    "            if t > 0:\n",
    "                std_dev = self.noise_schedule['sqrt_beta'][t]\n",
    "                noise = torch.randn_like(x, dtype=torch.float32)\n",
    "                x = mean + std_dev * noise\n",
    "            else:\n",
    "                x = mean\n",
    "\n",
    "        self.model.train()\n",
    "        return x\n",
    "\n",
    "# FID calculation helper\n",
    "class FID:\n",
    "    def __init__(self, config):\n",
    "        self.device = config.device\n",
    "        try:\n",
    "            self.inception_model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT, transform_input=False)\n",
    "        except TypeError:\n",
    "            self.inception_model = models.inception_v3(pretrained=True, transform_input=False)\n",
    "\n",
    "        self.inception_model.fc = nn.Identity()\n",
    "        self.inception_model.AuxLogits.fc = nn.Identity()\n",
    "        self.inception_model = self.inception_model.to(self.device)\n",
    "        self.inception_model.eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, loader):\n",
    "        features = []\n",
    "\n",
    "        for batch in tqdm(loader, desc=\"Extracting features\"):\n",
    "            if isinstance(batch, tuple) and len(batch) == 1:\n",
    "                imgs = batch[0]\n",
    "            elif isinstance(batch, list) and len(batch) == 1:\n",
    "                imgs = batch[0]\n",
    "            else:\n",
    "                imgs = batch\n",
    "\n",
    "            imgs = imgs.to(self.device)\n",
    "            if imgs.shape[1] == 1:\n",
    "                imgs = imgs.repeat(1, 3, 1, 1)\n",
    "            imgs = F.interpolate(imgs, size=(299, 299), mode='bilinear', align_corners=False, antialias=True)\n",
    "            imgs = (imgs + 1) / 2.0\n",
    "            inception_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            imgs = inception_normalize(imgs)\n",
    "            feat = self.inception_model(imgs)\n",
    "            if isinstance(feat, models.inception.InceptionOutputs):\n",
    "                feat = feat.logits\n",
    "            features.append(feat.cpu().numpy())\n",
    "\n",
    "        return np.concatenate(features, axis=0)\n",
    "\n",
    "    def calculate_fid(self, real_features, generated_features):\n",
    "        mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
    "        mu2, sigma2 = np.mean(generated_features, axis=0), np.cov(generated_features, rowvar=False)\n",
    "        sum_sq_diff = np.sum((mu1 - mu2)**2)\n",
    "        eps = 1e-6\n",
    "        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2) + eps * np.eye(sigma1.shape[0]), disp=False)\n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "        fid = sum_sq_diff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "        return fid\n",
    "\n",
    "# Helper functions\n",
    "def load_dataset(config):\n",
    "    try:\n",
    "        dataset = LensingDataset(config.data_path, config.image_size)\n",
    "        print(f\"Successfully loaded dataset with {len(dataset)} samples\")\n",
    "        if len(dataset) > 0:\n",
    "            sample = dataset[0]\n",
    "            print(f\"Sample shape: {sample.shape}, dtype: {sample.dtype}\")\n",
    "        else:\n",
    "            print(\"Dataset is empty!\")\n",
    "            return None\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        if not os.path.exists(config.data_path):\n",
    "            print(f\"Data directory '{config.data_path}' not found.\")\n",
    "            print(\"Please ensure the data is extracted correctly.\")\n",
    "        elif os.path.isdir(config.data_path):\n",
    "            try:\n",
    "                files = os.listdir(config.data_path)\n",
    "                print(f\"Files in {config.data_path}: {files[:10]}...\")\n",
    "                if not any(f.endswith('.npy') for f in files):\n",
    "                    print(\"No .npy files found in the directory.\")\n",
    "            except Exception as list_e:\n",
    "                print(f\"Could not list files in {config.data_path}: {list_e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def train(config):\n",
    "    dataset = load_dataset(config)\n",
    "    if dataset is None:\n",
    "        print(\"Dataset loading failed. Exiting training.\")\n",
    "        return None\n",
    "\n",
    "    num_workers = 2\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True, \n",
    "                           num_workers=num_workers, pin_memory=True if config.device==\"cuda\" else False)\n",
    "\n",
    "    diffusion = DiffusionModel(config)\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        epoch_losses = []\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.epochs}\", leave=True)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            loss = diffusion.train_step(batch)\n",
    "            epoch_losses.append(loss)\n",
    "            progress_bar.set_postfix({\"loss\": np.mean(epoch_losses[-20:])})\n",
    "\n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{config.epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Generate samples periodically\n",
    "        if (epoch + 1) % 10 == 0 or epoch == config.epochs - 1:\n",
    "            print(f\"Generating samples for epoch {epoch+1}...\")\n",
    "            samples = diffusion.sample(16)\n",
    "            samples = (samples + 1) / 2\n",
    "            samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            for i in range(16):\n",
    "                plt.subplot(4, 4, i+1)\n",
    "                plt.imshow(samples[i, 0].cpu().numpy(), cmap='viridis')\n",
    "                plt.axis('off')\n",
    "            plt.suptitle(f\"Samples Epoch {epoch+1}\", fontsize=16)\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            save_path = f\"samples_epoch_{epoch+1}.png\"\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"Saved samples to {save_path}\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Calculate FID\n",
    "            if True:  # Only calculate FID for the final epoch to save time\n",
    "                print(f\"Calculating FID for epoch {epoch+1}...\")\n",
    "                fid_calculator = FID(config)\n",
    "                \n",
    "                subset_indices = np.random.choice(len(dataset), min(256, len(dataset)), replace=False)\n",
    "                real_subset = torch.utils.data.Subset(dataset, subset_indices)\n",
    "                fid_batch_size = 32\n",
    "                real_loader = DataLoader(real_subset, batch_size=fid_batch_size, shuffle=False, num_workers=num_workers)\n",
    "                real_features = fid_calculator.extract_features(real_loader)\n",
    "                \n",
    "                n_fid_samples = len(real_subset)\n",
    "                generated_samples = diffusion.sample(n_fid_samples)\n",
    "                generated_dataset = torch.utils.data.TensorDataset(generated_samples)\n",
    "                generated_loader = DataLoader(generated_dataset, batch_size=fid_batch_size, shuffle=False)\n",
    "                generated_features = fid_calculator.extract_features(generated_loader)\n",
    "                \n",
    "                fid_score = fid_calculator.calculate_fid(real_features, generated_features)\n",
    "                print(f\"Epoch {epoch+1}, FID Score: {fid_score:.2f}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    model_save_path = \"gravitational_lensing_diffusion.pth\"\n",
    "    torch.save(diffusion.model.state_dict(), model_save_path)\n",
    "    print(f\"Saved trained model to {model_save_path}\")\n",
    "    \n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.grid(True)\n",
    "    loss_plot_path = \"training_loss.png\"\n",
    "    plt.savefig(loss_plot_path)\n",
    "    print(f\"Saved training loss plot to {loss_plot_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return diffusion\n",
    "\n",
    "# Inference with downloaded model\n",
    "class DiffusionInference:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = UNet(config).to(config.device)\n",
    "        self.noise_schedule = get_noise_schedule(config)\n",
    "\n",
    "        print(f\"Loading model from {config.model_path}...\")\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(config.model_path, map_location=config.device))\n",
    "            print(\"Model loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n_samples, size=None):\n",
    "        if size is None:\n",
    "            size = (self.config.channels, self.config.image_size, self.config.image_size)\n",
    "\n",
    "        x = torch.randn((n_samples, *size), device=self.config.device, dtype=torch.float32)\n",
    "\n",
    "        for t in tqdm(reversed(range(self.config.timesteps)), desc=\"Sampling\", total=self.config.timesteps):\n",
    "            t_tensor = torch.full((n_samples,), t, device=self.config.device, dtype=torch.long)\n",
    "            predicted_noise = self.model(x, t_tensor)\n",
    "            alpha_t = self.noise_schedule['alpha'][t]\n",
    "            alpha_t_bar = self.noise_schedule['alpha_bar'][t]\n",
    "            beta_t = self.noise_schedule['beta'][t]\n",
    "            sqrt_one_minus_alpha_t_bar = self.noise_schedule['sqrt_one_minus_alpha_bar'][t]\n",
    "            sqrt_recip_alpha_t = torch.sqrt(1.0 / alpha_t)\n",
    "            mean = sqrt_recip_alpha_t * (x - (beta_t / sqrt_one_minus_alpha_t_bar) * predicted_noise)\n",
    "\n",
    "            if t > 0:\n",
    "                std_dev = self.noise_schedule['sqrt_beta'][t]\n",
    "                noise = torch.randn_like(x, dtype=torch.float32)\n",
    "                x = mean + std_dev * noise\n",
    "            else:\n",
    "                x = mean\n",
    "\n",
    "        return x\n",
    "\n",
    "def download_and_infer():\n",
    "    # Download model from HuggingFace\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=\"oussamaor/gravlens\",\n",
    "        filename=\"model.pth\"\n",
    "    )\n",
    "    print(\"Model downloaded to:\", model_path)\n",
    "    \n",
    "    # Set up config for inference\n",
    "    config.model_path = model_path\n",
    "    \n",
    "    # Generate samples from the downloaded model\n",
    "    diffusion = DiffusionInference(config)\n",
    "    n_samples = 16\n",
    "    samples = diffusion.sample(n_samples)\n",
    "    samples = (samples + 1) / 2\n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "    # Visualize samples\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(samples[i, 0].cpu().numpy(), cmap='viridis')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Generated Samples from Pretrained Model\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(\"pretrained_samples.png\")\n",
    "    plt.show()\n",
    "\n",
    "def calculate_fid_with_pretrained():\n",
    "    # Ensure the model is downloaded\n",
    "    if config.model_path is None:\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=\"oussamaor/gravlens\",\n",
    "            filename=\"model.pth\"\n",
    "        )\n",
    "        config.model_path = model_path\n",
    "    \n",
    "    # Load dataset and check if it exists\n",
    "    dataset = load_dataset(config)\n",
    "    if dataset is None:\n",
    "        print(\"Cannot calculate FID: dataset loading failed\")\n",
    "        return\n",
    "    \n",
    "    # Initialize diffusion and FID calculator\n",
    "    diffusion = DiffusionInference(config)\n",
    "    fid_calculator = FID(config)\n",
    "    \n",
    "    # Sample subset of real data\n",
    "    subset_size = min(config.fid_n_samples, len(dataset))\n",
    "    subset_indices = np.random.choice(len(dataset), subset_size, replace=False)\n",
    "    real_subset = torch.utils.data.Subset(dataset, subset_indices)\n",
    "    real_loader = DataLoader(real_subset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Extract features\n",
    "    real_features = fid_calculator.extract_features(real_loader)\n",
    "    \n",
    "    # Generate samples and extract features\n",
    "    generated_samples = diffusion.sample(subset_size)\n",
    "    generated_dataset = TensorDataset(generated_samples)\n",
    "    generated_loader = DataLoader(generated_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    generated_features = fid_calculator.extract_features(generated_loader)\n",
    "    \n",
    "    # Calculate FID\n",
    "    fid_score = fid_calculator.calculate_fid(real_features, generated_features)\n",
    "    print(f\"FID Score with pretrained model: {fid_score:.2f}\")\n",
    "    return fid_score\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    print(f\"Using device: {config.device}\")\n",
    "    \n",
    "    # You can choose to either train or infer\n",
    "    train_mode = False  # Set to True to train, False to use pretrained\n",
    "    if train_mode:\n",
    "        print(\"Training diffusion model for gravitational lensing...\")\n",
    "        diffusion_model = train(config)\n",
    "        \n",
    "        if diffusion_model is not None:\n",
    "            print(\"Generating final samples...\")\n",
    "            final_samples = diffusion_model.sample(16)\n",
    "            final_samples = (final_samples + 1) / 2\n",
    "            final_samples = final_samples.clamp(0.0, 1.0)\n",
    "            \n",
    "            plt.figure(figsize=(12, 12))\n",
    "            for i in range(16):\n",
    "                plt.subplot(4, 4, i+1)\n",
    "                plt.imshow(final_samples[i, 0].cpu().numpy(), cmap='viridis')\n",
    "                plt.axis('off')\n",
    "            plt.suptitle(\"Final Generated Samples\", fontsize=16)\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.savefig(\"final_samples.png\")\n",
    "            print(\"Saved final generated samples to final_samples.png\")\n",
    "            plt.show()\n",
    "    else:\n",
    "        # Use pretrained model from HuggingFace\n",
    "        print(\"Using pretrained model from HuggingFace\")\n",
    "        download_and_infer()\n",
    "        \n",
    "        # Optionally calculate FID score\n",
    "        calculate_fid = True  # Set to False to skip FID calculation\n",
    "        if calculate_fid:\n",
    "            fid_score = calculate_fid_with_pretrained()\n",
    "            print(f\"FID Score: {fid_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
